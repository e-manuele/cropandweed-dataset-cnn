{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Object Detection\n",
    "\n",
    "Object detection is a phenomenon in computer vision that involves the detection of various objects in digital images or videos. Some of the objects detected include people, cars, chairs, stones, buildings, and animals.\n",
    "\n",
    "This phenomenon seeks to answer two basic questions:\n",
    "\n",
    "1. What is the object? This question seeks to identify the object in a specific image.\n",
    "2. Where is it? This question seeks to establish the exact location of the object within the image.\n"
   ],
   "metadata": {
    "id": "IyakSuwnkJfR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#YOLO Introduction\n",
    "YOLO is an algorithm that uses neural networks to provide real-time object etection. This algorithm is popular because of its speed and accuracy. It has\n",
    "been used in various applications to detect traffic signals, people, parking meters, and animals. YOLO is an abbreviation for the term ‘You Only Look Once’. This is an algorithm that detects and recognizes various objects in a picture (in real-time). Object detection in YOLO is done as a regression problem and provides the class probabilities of the detected images."
   ],
   "metadata": {
    "id": "ViiCQlKX-khZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, the image is divided into various grids. Each grid has a dimension of S x S. The following image shows how an input image is divided into grids, in which there are many grid cells of equal dimension. Every grid cell will detect objects that appear within them.\n",
    "\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1VrRY7N7NOKKu-5NrjI-Gshy1CumVCoNX)"
   ],
   "metadata": {
    "id": "1regkYKUCRUm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then another technique will be used called Intersection over union (IOU), which is a phenomenon in object detection that describes how boxes overlap. YOLO uses IOU to provide an output box that surrounds the objects perfectly.\n",
    "\n",
    "One issue that might happen is when the algorithm predicts several bounding boxes for one class. We could select only one box per class, that has the highest probability, but what if there are more objects of one class on the image (for example a few cats). Because of that,  a non-max suppression algorithm is used. First, we take the box with the maximum probability. After that, we compare the box with all other boxes of that particular class using IOU. If the IoU is higher than the predefined threshold (for example 0.5), then the box with a smaller probability is suppressed or excluded. It means that two boxes with high IoU values probably indicate the same object on the image, so we exclude the box with a lower probability. This process is repeated until all boxes are taken as object prediction or excluded.\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1kP80jh7iUI-OG4F1pGMDKEVoSmUxvuB7)"
   ],
   "metadata": {
    "id": "7nb5j9Z0Ci2c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test the pretrained yolo model on a sample image."
   ],
   "metadata": {
    "id": "9MMAHxSeYrY5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'"
   ],
   "metadata": {
    "id": "aVL6canH8vrX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fine Tuning Yolo on a new dataset\n",
    "\n",
    "Now we want to use a new dataset to fine tune yolo on the dataset for using it for detecting some other kinds of object which may not exist in the origin dataset on which yolo is trained.\n",
    "\n",
    "Here we want to fine tune yolo model on a Furniture dataset, which can be seen [here](https://universe.roboflow.com/mokhamed-nagy-u69zl/furniture-detection-qiufc/dataset/20). This dataset contains more than 7000 images of different furniture and their related annotations.\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1s3ZRTHVo8BRdgSjFAwgkefJqI5O86ek2)\n",
    "\n",
    "First we download the dataset and prepare the data."
   ],
   "metadata": {
    "id": "_CE4V1IgNZZd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dfoJdE7N47e"
   },
   "outputs": [],
   "source": [
    "!wget -O data.zip 'https://universe.roboflow.com/ds/yPJiNb0k0T?key=aZSRk47xb5'"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip --qq '/content/data.zip'"
   ],
   "metadata": {
    "id": "_OR2CM3N-wDJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The annotation of the data is like this:\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1s-qWMRNl0SU7jCtPkIYne2CLfjUawbHd)"
   ],
   "metadata": {
    "id": "CLz4aA0LvJkV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we prepare the yolo model for the training procedure. (Make sure to modify the yaml file paths with the correct paths)"
   ],
   "metadata": {
    "id": "xl2oUgIYOQv-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install ultralytics"
   ],
   "metadata": {
    "id": "EfkMBepWQt6O"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!yolo task=detect mode=train model=yolov8n.pt imgsz=640 data='/content/data.yaml' epochs=50 batch=86 name=yolov8n_furniture"
   ],
   "metadata": {
    "id": "USnxGa34R02r"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check the performance of the model on a sample image"
   ],
   "metadata": {
    "id": "QnGCbblqmADJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image"
   ],
   "metadata": {
    "id": "Y_Ry46739ZUr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "names = ['Bed', 'Cabinet', 'Carpet', 'Ceramic floor', 'Chair', 'Closet', 'Cupboard', 'Curtains', 'Dining Table',\n",
    "            'Door', 'Frame', 'Futec frame', 'Futech tiles', 'Gypsum Board', 'Lamp', 'Nightstand', 'Shelf', 'Sideboard',\n",
    "            'Sofa', 'TV stand', 'Table', 'Transparent Closet', 'Wall Panel', 'Window', 'Wooden floor']"
   ],
   "metadata": {
    "id": "Fg5o7UXnBNiW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "weights_path = \"/content/runs/detect/yolov8n_furniture/weights/best.pt\"\n",
    "model = YOLO(weights_path)"
   ],
   "metadata": {
    "id": "V5FWIxEp_VVO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "img_path = '/content/test/images/-1-_jpg.rf.8fa48d61117eb985d8be50da70ee0911.jpg'\n",
    "img = Image.open(img_path)\n",
    "outputs = model.predict(img, conf=.1)[0]"
   ],
   "metadata": {
    "id": "Uvh4rwlj_aMe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "xyxys= []\n",
    "confidences = []\n",
    "classes = []\n",
    "for result in outputs:\n",
    "  boxes = result.boxes.cpu().numpy()\n",
    "  xyxys.append(boxes.xyxy)\n",
    "  confidences.append(boxes.conf)\n",
    "  classes.append(boxes.cls)"
   ],
   "metadata": {
    "id": "veRgTeANbQvh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "# print(img.shape)\n",
    "for xy_ in xyxys:\n",
    "  for idx , xy in enumerate(xy_):\n",
    "    cv2.putText(img, text=str(confidences[0][idx]), org=(int(xy[0]) + 10,int(xy[1])+20), fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=.5, color=(0,255,0), thickness=1)\n",
    "    cv2.putText(img, text=names[int(classes[0][idx])], org=(int(xy[0]) + 10,int(xy[1])+35), fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=.5, color=(0,255,0), thickness=1)\n",
    "    cv2.rectangle(img, (int(xy[0]), int(xy[1])), (int(xy[2]), int(xy[3])), (0, 255, 0, 255), 2)\n",
    "cv2_imshow(img)"
   ],
   "metadata": {
    "id": "ZE9JBPz5dha2"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
