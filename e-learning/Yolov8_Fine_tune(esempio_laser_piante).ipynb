{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyakSuwnkJfR"
   },
   "source": [
    "# Object Detection\n",
    "\n",
    "Object detection is a phenomenon in computer vision that involves the detection of various objects in digital images or videos. Some of the objects detected include people, cars, chairs, stones, buildings, and animals.\n",
    "\n",
    "This phenomenon seeks to answer two basic questions:\n",
    "\n",
    "1. What is the object? This question seeks to identify the object in a specific image.\n",
    "2. Where is it? This question seeks to establish the exact location of the object within the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViiCQlKX-khZ"
   },
   "source": [
    "#YOLO Introduction\n",
    "YOLO is an algorithm that uses neural networks to provide real-time object etection. This algorithm is popular because of its speed and accuracy. It has\n",
    "been used in various applications to detect traffic signals, people, parking meters, and animals. YOLO is an abbreviation for the term ‘You Only Look Once’. This is an algorithm that detects and recognizes various objects in a picture (in real-time). Object detection in YOLO is done as a regression problem and provides the class probabilities of the detected images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1regkYKUCRUm"
   },
   "source": [
    "First, the image is divided into various grids. Each grid has a dimension of S x S. The following image shows how an input image is divided into grids, in which there are many grid cells of equal dimension. Every grid cell will detect objects that appear within them.\n",
    "\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1VrRY7N7NOKKu-5NrjI-Gshy1CumVCoNX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nb5j9Z0Ci2c"
   },
   "source": [
    "Then another technique will be used called Intersection over union (IOU), which is a phenomenon in object detection that describes how boxes overlap. YOLO uses IOU to provide an output box that surrounds the objects perfectly.\n",
    "\n",
    "One issue that might happen is when the algorithm predicts several bounding boxes for one class. We could select only one box per class, that has the highest probability, but what if there are more objects of one class on the image (for example a few cats). Because of that,  a non-max suppression algorithm is used. First, we take the box with the maximum probability. After that, we compare the box with all other boxes of that particular class using IOU. If the IoU is higher than the predefined threshold (for example 0.5), then the box with a smaller probability is suppressed or excluded. It means that two boxes with high IoU values probably indicate the same object on the image, so we exclude the box with a lower probability. This process is repeated until all boxes are taken as object prediction or excluded.\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1kP80jh7iUI-OG4F1pGMDKEVoSmUxvuB7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MMAHxSeYrY5"
   },
   "source": [
    "Let's test the pretrained yolo model on a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T10:35:09.555776500Z",
     "start_time": "2023-12-14T10:34:06.216580800Z"
    },
    "id": "aVL6canH8vrX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.151-py3-none-any.whl (616 kB)\n",
      "  Downloading ultralytics-8.0.150-py3-none-any.whl (614 kB)\n",
      "  Downloading ultralytics-8.0.149-py3-none-any.whl (614 kB)\n",
      "  Downloading ultralytics-8.0.148-py3-none-any.whl (606 kB)\n",
      "  Downloading ultralytics-8.0.147-py3-none-any.whl (606 kB)\n",
      "  Downloading ultralytics-8.0.146-py3-none-any.whl (605 kB)\n",
      "  Downloading ultralytics-8.0.145-py3-none-any.whl (605 kB)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (0.11.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (2.25.0)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (3.3.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (1.5.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (8.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (5.3.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (0.14.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (5.7.2)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2020.12.5)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.19.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.2->ultralytics) (1.15.0)\n",
      "Collecting opencv-python>=4.6.0\n",
      "  Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.19.2)\n",
      "Collecting pandas>=1.1.4\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-win_amd64.whl (10.0 MB)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.19.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.1)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: six in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.2->ultralytics) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.19.2)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (3.3.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (8.0.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.19.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (2.25.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.7.4.3)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\emanuele\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Collecting tqdm>=4.64.0\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\emanuele\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.3)\n",
      "Installing collected packages: pandas, tqdm, py-cpuinfo, opencv-python, ultralytics\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.3\n",
      "    Uninstalling pandas-1.1.3:\n",
      "      Successfully uninstalled pandas-1.1.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.54.0\n",
      "    Uninstalling tqdm-4.54.0:\n",
      "      Successfully uninstalled tqdm-4.54.0\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.5.2.54\n",
      "    Uninstalling opencv-python-4.5.2.54:\n",
      "      Successfully uninstalled opencv-python-4.5.2.54\n",
      "Successfully installed opencv-python-4.8.1.78 pandas-1.3.5 py-cpuinfo-9.0.0 tqdm-4.66.1 ultralytics-8.0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
      "\n",
      "  0%|          | 0.00/6.23M [00:00<?, ?B/s]\n",
      "  8%|8         | 536k/6.23M [00:00<00:01, 4.86MB/s]\n",
      " 28%|##7       | 1.73M/6.23M [00:00<00:00, 9.15MB/s]\n",
      " 51%|#####     | 3.16M/6.23M [00:00<00:00, 11.7MB/s]\n",
      " 69%|######9   | 4.30M/6.23M [00:00<00:00, 4.49MB/s]\n",
      " 88%|########8 | 5.49M/6.23M [00:00<00:00, 5.51MB/s]\n",
      "100%|##########| 6.23M/6.23M [00:01<00:00, 6.25MB/s]\n",
      "Ultralytics YOLOv8.0.145  Python-3.7.9 torch-1.13.1+cpu CPU (Intel Core(TM) i7-8565U 1.80GHz)\n",
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (7)YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n",
      " Download failure, retrying 1/3 https://ultralytics.com/images/bus.jpg...\n",
      " Download failure, retrying 2/3 https://ultralytics.com/images/bus.jpg...\n",
      " Download failure, retrying 3/3 https://ultralytics.com/images/bus.jpg...\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\utils\\downloads.py\", line 160, in safe_download\n",
      "    r = subprocess.run(['curl', '-#', f'-{s}L', url, '-o', f, '--retry', '3', '-C', '-']).returncode\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\subprocess.py\", line 488, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\subprocess.py\", line 800, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\subprocess.py\", line 1148, in _execute_child\n",
      "    args = list2cmdline(args)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\subprocess.py\", line 555, in list2cmdline\n",
      "    needquote = (\" \" in arg) or (\"\\t\" in arg) or not arg\n",
      "TypeError: argument of type 'WindowsPath' is not iterable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Emanuele\\anaconda3\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 423, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\model.py\", line 246, in predict\n",
      "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 202, in predict_cli\n",
      "    for _ in gen:  # running CLI inference without accumulating any outputs (do not modify)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 43, in generator_context\n",
      "    response = gen.send(None)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 229, in stream_inference\n",
      "    self.setup_source(source if source is not None else self.args.source)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\predictor.py\", line 210, in setup_source\n",
      "    self.dataset = load_inference_source(source=source, imgsz=self.imgsz, vid_stride=self.args.vid_stride)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\data\\build.py\", line 150, in load_inference_source\n",
      "    source, webcam, screenshot, from_img, in_memory, tensor = check_source(source)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\data\\build.py\", line 122, in check_source\n",
      "    source = check_file(source)  # download\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\utils\\checks.py\", line 325, in check_file\n",
      "    downloads.safe_download(url=url, file=file, unzip=False)\n",
      "  File \"c:\\users\\emanuele\\anaconda3\\lib\\site-packages\\ultralytics\\utils\\downloads.py\", line 188, in safe_download\n",
      "    raise ConnectionError(emojis(f'\\u274c  Download failure for {url}. Retry limit reached.')) from e\n",
      "ConnectionError:   Download failure for https://ultralytics.com/images/bus.jpg. Retry limit reached.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CE4V1IgNZZd"
   },
   "source": [
    "# Fine Tuning Yolo on a new dataset\n",
    "\n",
    "Now we want to use a new dataset to fine tune yolo on the dataset for using it for detecting some other kinds of object which may not exist in the origin dataset on which yolo is trained.\n",
    "\n",
    "Here we want to fine tune yolo model on a Furniture dataset, which can be seen [here](https://universe.roboflow.com/mokhamed-nagy-u69zl/furniture-detection-qiufc/dataset/20). This dataset contains more than 7000 images of different furniture and their related annotations.\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1s3ZRTHVo8BRdgSjFAwgkefJqI5O86ek2)\n",
    "\n",
    "First we download the dataset and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T10:35:09.688927800Z",
     "start_time": "2023-12-14T10:35:09.575368500Z"
    },
    "id": "4dfoJdE7N47e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" non Š riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n"
     ]
    }
   ],
   "source": [
    "!wget -O data.zip 'https://universe.roboflow.com/ds/yPJiNb0k0T?key=aZSRk47xb5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OR2CM3N-wDJ"
   },
   "outputs": [],
   "source": [
    "!unzip --qq '/content/data.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLz4aA0LvJkV"
   },
   "source": [
    "The annotation of the data is like this:\n",
    "\n",
    "![image](https://drive.google.com/uc?id=1s-qWMRNl0SU7jCtPkIYne2CLfjUawbHd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xl2oUgIYOQv-"
   },
   "source": [
    "Now we prepare the yolo model for the training procedure. (Make sure to modify the yaml file paths with the correct paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfkMBepWQt6O"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USnxGa34R02r"
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8n.pt imgsz=640 data='/content/data.yaml' epochs=50 batch=86 name=yolov8n_furniture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnGCbblqmADJ"
   },
   "source": [
    "Let's check the performance of the model on a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_Ry46739ZUr"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fg5o7UXnBNiW"
   },
   "outputs": [],
   "source": [
    "names = ['Bed', 'Cabinet', 'Carpet', 'Ceramic floor', 'Chair', 'Closet', 'Cupboard', 'Curtains', 'Dining Table',\n",
    "            'Door', 'Frame', 'Futec frame', 'Futech tiles', 'Gypsum Board', 'Lamp', 'Nightstand', 'Shelf', 'Sideboard',\n",
    "            'Sofa', 'TV stand', 'Table', 'Transparent Closet', 'Wall Panel', 'Window', 'Wooden floor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V5FWIxEp_VVO"
   },
   "outputs": [],
   "source": [
    "weights_path = \"/content/runs/detect/yolov8n_furniture/weights/best.pt\"\n",
    "model = YOLO(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uvh4rwlj_aMe"
   },
   "outputs": [],
   "source": [
    "img_path = '/content/test/images/-1-_jpg.rf.8fa48d61117eb985d8be50da70ee0911.jpg'\n",
    "img = Image.open(img_path)\n",
    "outputs = model.predict(img, conf=.1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veRgTeANbQvh"
   },
   "outputs": [],
   "source": [
    "xyxys= []\n",
    "confidences = []\n",
    "classes = []\n",
    "for result in outputs:\n",
    "  boxes = result.boxes.cpu().numpy()\n",
    "  xyxys.append(boxes.xyxy)\n",
    "  confidences.append(boxes.conf)\n",
    "  classes.append(boxes.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE9JBPz5dha2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "# print(img.shape)\n",
    "for xy_ in xyxys:\n",
    "  for idx , xy in enumerate(xy_):\n",
    "    cv2.putText(img, text=str(confidences[0][idx]), org=(int(xy[0]) + 10,int(xy[1])+20), fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=.5, color=(0,255,0), thickness=1)\n",
    "    cv2.putText(img, text=names[int(classes[0][idx])], org=(int(xy[0]) + 10,int(xy[1])+35), fontFace= cv2.FONT_HERSHEY_SIMPLEX, fontScale=.5, color=(0,255,0), thickness=1)\n",
    "    cv2.rectangle(img, (int(xy[0]), int(xy[1])), (int(xy[2]), int(xy[3])), (0, 255, 0, 255), 2)\n",
    "cv2_imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
